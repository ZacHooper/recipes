{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytesseract import pytesseract\n",
    "import spacy\n",
    "import cv2\n",
    "import numpy as np\n",
    "from spacy.language import Language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tesseract = r\"/opt/homebrew/opt/tesseract/bin/tesseract\"\n",
    "pytesseract.tesseract_cmd = path_to_tesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"sample_data/Thali_sweetcorn.png\"\n",
    "# image_path = r\"sample_data/Tahini-test_kitchen.png\"\n",
    "img = cv2.imread(image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- dilation on the green channel ---\n",
    "dilated_img = cv2.dilate(img[:, :, 1], np.ones((7, 7), np.uint8))\n",
    "bg_img = cv2.medianBlur(dilated_img, 21)\n",
    "\n",
    "# --- finding absolute difference to preserve edges ---\n",
    "diff_img = 255 - cv2.absdiff(img[:, :, 1], bg_img)\n",
    "\n",
    "# --- normalizing between 0 to 255 ---\n",
    "norm_img = cv2.normalize(\n",
    "    diff_img, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8UC1\n",
    ")\n",
    "\n",
    "# --- Otsu threshold ---\n",
    "th = cv2.threshold(norm_img, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"SERVES 4\\n\\n520 g (1 Ib 2 02) tin of\\nsweetcorn, drained\\n\\n3 tbsp vegetable oil\\n\\npinch of asafoetida\\n\\n1 heaped tsp black\\nmustard seeds\\n\\n1 tsp ground turmeric\\n\\nsalt, to taste\\n\\n1 tbsp finely chopped\\ncoriander (cilantro)\\n\\n1 tbsp roasted peanuts,\\ncrushed\\n\\njuice of % lime\\n\\nFor the chilli and ginger paste\\n\\n1 green bird's-eye chilli\\n\\n3 garlic cloves, roughly\\nchopped\\n\\n5 cm (2 in) ginger root,\\nroughly chopped\\n\\nGUJARATI VAGHARA MAKKAI\\nSpicy Sweetcorn with\\nGinger & Green Chilli\\n\\nStir-fried sweetcorn with ginger, green chilli and\\nturmeric. Simple quick and delicious, this stir-fry is\\na must to accompany every thali. I’ve used tinned\\nsweetcorn for this recipe, which is readily available.\\n\\nFirst make the chilli and ginger paste by placing all the\\ningredients into a blender, along with 3 tablespoons of the\\nsweetcorn, and blitz to a coarse paste. Set aside.\\n\\nHeat the oil in a large frying pan (skillet) over a medium heat.\\nAdd the asafoetida and mustard seeds, and fry for a few\\nseconds until they sputter.\\n\\nAdd the prepared chilli and ginger paste and fry for 1 minute,\\nstirring well. Add the turmeric and stir, then add the remaining\\nsweetcorn and fry for 2 minutes. Reduce the heat to low,\\nseason, and add the fresh coriander and crushed peanuts.\\nCover and cook for 1 more minute. Finish with the lime juice\\nand serve warm.\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = pytesseract.image_to_string(th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialise NLP Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Sentensizer to recognise line breaks as a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@Language.component(\"set_custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text == \"\\n\\n\":\n",
    "            doc[token.i].is_sent_start = True\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.set_custom_boundaries(doc)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(\"set_custom_boundaries\", before=\"parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process Text with Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[SERVES 4],\n",
       " [520 g (1 Ib 2 02) tin of\n",
       "  sweetcorn, drained],\n",
       " [3 tbsp vegetable oil],\n",
       " [pinch of asafoetida],\n",
       " [1 heaped tsp black\n",
       "  mustard seeds],\n",
       " [1 tsp ground turmeric],\n",
       " [salt, to taste],\n",
       " [1 tbsp finely chopped\n",
       "  coriander (cilantro)],\n",
       " [1 tbsp roasted peanuts,\n",
       "  crushed],\n",
       " [juice of % lime],\n",
       " [For the chilli and ginger paste],\n",
       " [1 green bird's-eye chilli],\n",
       " [3 garlic cloves, roughly\n",
       "  chopped],\n",
       " [5 cm (2 in) ginger root,\n",
       "  roughly chopped],\n",
       " [GUJARATI VAGHARA MAKKAI\n",
       "  Spicy Sweetcorn with\n",
       "  Ginger & Green Chilli],\n",
       " [Stir-fried sweetcorn with ginger, green chilli and\n",
       "  turmeric.,\n",
       "  Simple quick and delicious, this stir-fry is\n",
       "  a must to accompany every thali.,\n",
       "  I’ve used tinned\n",
       "  sweetcorn for this recipe, which is readily available.],\n",
       " [First make the chilli and ginger paste by placing all the\n",
       "  ingredients into a blender, along with 3 tablespoons of the\n",
       "  sweetcorn, and blitz to a coarse paste.,\n",
       "  Set aside.],\n",
       " [Heat the oil in a large frying pan (skillet) over a medium heat.,\n",
       "  Add the asafoetida and mustard seeds, and fry for a few\n",
       "  seconds until they sputter.],\n",
       " [Add the prepared chilli and ginger paste and fry for 1 minute,\n",
       "  stirring well.,\n",
       "  Add the turmeric and stir, then add the remaining\n",
       "  sweetcorn and fry for 2 minutes.,\n",
       "  Reduce the heat to low,\n",
       "  season, and add the fresh coriander and crushed peanuts.,\n",
       "  Cover and cook for 1 more minute.,\n",
       "  Finish with the lime juice\n",
       "  and serve warm.]]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find paragraphs by splitting on \"whitespace\" sentences\n",
    "paragraphs = []\n",
    "paragraph = []\n",
    "for sent in doc.sents:\n",
    "    if len(sent) <= 1:\n",
    "        paragraphs.append(paragraph)\n",
    "        paragraph = []\n",
    "        continue\n",
    "    paragraph.append(sent)\n",
    "paragraphs.append(paragraph)\n",
    "paragraphs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge paragraphs into a single string\n",
    "texts = []\n",
    "for paragraph in paragraphs:\n",
    "    text = \"\"\n",
    "    if len(paragraph) > 1:\n",
    "        text = \" \".join([sent.text for sent in paragraph])\n",
    "    else:\n",
    "        text = paragraph[0].text\n",
    "    \n",
    "    # remove \\n\n",
    "    text = text.replace(\"\\n\", \" \")\n",
    "    texts.append(text)\n",
    "\n",
    "# write text to file\n",
    "with open(\"output.txt\", \"w\") as f:\n",
    "    for text in texts:\n",
    "        f.write(text + \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert `\\n` in the text to a space (no more need for line breaks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E178] Each pattern should be a list of dicts, but got: {'ORTH': '\\n'}. Maybe you accidentally passed a single pattern to Matcher.add instead of a list of patterns? If you only want to add one pattern, make sure to wrap it in a list. For example: `matcher.add('\n', [pattern])`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [47], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m token \u001b[39min\u001b[39;00m paragraphs[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]:\n\u001b[1;32m     16\u001b[0m     \u001b[39mif\u001b[39;00m token\u001b[39m.\u001b[39mtext \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m:\n\u001b[0;32m---> 17\u001b[0m         replace_word(token, \u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     19\u001b[0m paragraphs[\u001b[39m1\u001b[39m][\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtext\n",
      "Cell \u001b[0;32mIn [47], line 3\u001b[0m, in \u001b[0;36mreplace_word\u001b[0;34m(orig_text, replacement)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mreplace_word\u001b[39m(orig_text, replacement):\n\u001b[1;32m      2\u001b[0m     matcher \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39mmatcher\u001b[39m.\u001b[39mMatcher(nlp\u001b[39m.\u001b[39mvocab)\n\u001b[0;32m----> 3\u001b[0m     matcher\u001b[39m.\u001b[39;49madd(\u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m, [{\u001b[39m\"\u001b[39;49m\u001b[39mORTH\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m}])\n\u001b[1;32m      4\u001b[0m     tok \u001b[39m=\u001b[39m nlp(orig_text)\n\u001b[1;32m      5\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Personal/Projects/recipes/venv/lib/python3.10/site-packages/spacy/matcher/matcher.pyx:122\u001b[0m, in \u001b[0;36mspacy.matcher.matcher.Matcher.add\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E178] Each pattern should be a list of dicts, but got: {'ORTH': '\\n'}. Maybe you accidentally passed a single pattern to Matcher.add instead of a list of patterns? If you only want to add one pattern, make sure to wrap it in a list. For example: `matcher.add('\n', [pattern])`"
     ]
    }
   ],
   "source": [
    "def replace_word(orig_text, replacement):\n",
    "    matcher = spacy.matcher.Matcher(nlp.vocab)\n",
    "    matcher.add(\"\\n\", [{\"ORTH\": \"\\n\"}])\n",
    "    tok = nlp(orig_text)\n",
    "    text = ''\n",
    "    buffer_start = 0\n",
    "    for _, match_start, _ in matcher(tok):\n",
    "        if match_start > buffer_start:  # If we've skipped over some tokens, let's add those in (with trailing whitespace if available)\n",
    "            text += tok[buffer_start: match_start].text + tok[match_start - 1].whitespace_\n",
    "        text += replacement + tok[match_start].whitespace_  # Replace token, with trailing whitespace if available\n",
    "        buffer_start = match_start + 1\n",
    "    text += tok[buffer_start:].text\n",
    "    return text\n",
    "\n",
    "for token in paragraphs[1][0]:\n",
    "    if token.text == \"\\n\":\n",
    "        replace_word(token, \" \")\n",
    "\n",
    "paragraphs[1][0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Amount of Serves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_serving_sentences(paragraphs: list) -> str:\n",
    "    for paragraph in paragraphs:\n",
    "        if len(paragraph) > 1:\n",
    "            continue\n",
    "        if \"SERVES\" in paragraph[0].text:\n",
    "            return paragraph[0]\n",
    "    \n",
    "\n",
    "def get_serving_amount(serving_sentence) -> str:\n",
    "    for token in serving_sentence:\n",
    "        if token.pos_ == \"NUM\":\n",
    "            return token\n",
    "\n",
    "\n",
    "serving_sentence = get_serving_sentences(paragraphs)\n",
    "serving_amount = get_serving_amount(serving_sentence)\n",
    "serving_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract ingredients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[520 g (1 Ib 2 02) tin of\n",
      "sweetcorn, drained], [3 tbsp vegetable oil], [pinch of asafoetida], [1 heaped tsp black\n",
      "mustard seeds], [1 tsp ground turmeric], [salt, to taste], [1 tbsp finely chopped\n",
      "coriander (cilantro)], [1 tbsp roasted peanuts,\n",
      "crushed], [juice of % lime], [1 green bird's-eye chilli], [3 garlic cloves, roughly\n",
      "chopped], [5 cm (2 in) ginger root,\n",
      "roughly chopped]]\n"
     ]
    }
   ],
   "source": [
    "def is_ingredient_sent(paragraph: list) -> bool:\n",
    "    # Ingredients only have one Span in the paragraph\n",
    "    if len(paragraph) > 1:\n",
    "        return False\n",
    "\n",
    "    ingredient_span = paragraph[0]\n",
    "    \n",
    "    # Only Ingredient's begin with a number\n",
    "    if list(ingredient_span)[0].pos_ == \"NUM\":\n",
    "        return True\n",
    "\n",
    "    # Ingredients often follow the format of: [AMOUNT] of [optional adjetive] [INGREDIENT] eg pinch of salt, ROOT prep ... pobj\n",
    "    serving_sentence_list = list(ingredient_span)\n",
    "    if (\n",
    "        serving_sentence_list[0].dep_ == \"ROOT\"\n",
    "        and serving_sentence_list[1].dep_ == \"prep\"\n",
    "        and serving_sentence_list[-1].dep_ == \"pobj\"\n",
    "    ):\n",
    "        return True\n",
    "\n",
    "    # Ingredient sometimes listed with some extra steps but no additional nouns. Eg \"salt, to taste\"\n",
    "    check_if_noun = lambda token: token.pos_ == \"NOUN\"\n",
    "    if serving_sentence_list[0].pos_ == \"NOUN\" and not any([check_if_noun(token) for token in serving_sentence_list[1:]]):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "        \n",
    "ingredients_indexes = [idx for idx, p in enumerate(paragraphs) if is_ingredient_sent(p)]\n",
    "ingredients = [paragraphs[idx] for idx in ingredients_indexes]\n",
    "print(ingredients)\n",
    "no_ingred_paragraphs = [p for idx, p in enumerate(paragraphs) if idx not in ingredients_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[SERVES 4],\n",
       " [For the chilli and ginger paste],\n",
       " [GUJARATI VAGHARA MAKKAI\n",
       "  Spicy Sweetcorn with\n",
       "  Ginger & Green Chilli],\n",
       " [Stir-fried sweetcorn with ginger, green chilli and\n",
       "  turmeric.,\n",
       "  Simple quick and delicious, this stir-fry is\n",
       "  a must to accompany every thali.,\n",
       "  I’ve used tinned\n",
       "  sweetcorn for this recipe, which is readily available.],\n",
       " [First make the chilli and ginger paste by placing all the\n",
       "  ingredients into a blender, along with 3 tablespoons of the\n",
       "  sweetcorn, and blitz to a coarse paste.,\n",
       "  Set aside.],\n",
       " [Heat the oil in a large frying pan (skillet) over a medium heat.,\n",
       "  Add the asafoetida and mustard seeds, and fry for a few\n",
       "  seconds until they sputter.],\n",
       " [Add the prepared chilli and ginger paste and fry for 1 minute,\n",
       "  stirring well.,\n",
       "  Add the turmeric and stir, then add the remaining\n",
       "  sweetcorn and fry for 2 minutes.,\n",
       "  Reduce the heat to low,\n",
       "  season, and add the fresh coriander and crushed peanuts.,\n",
       "  Cover and cook for 1 more minute.,\n",
       "  Finish with the lime juice\n",
       "  and serve warm.]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_ingred_paragraphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f2cc5a833e7fab22ef484b6e8eabe6cbae6031282a360d3203fe211a727ee232"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
